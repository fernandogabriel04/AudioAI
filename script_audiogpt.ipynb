{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|█████████████████████████████████████| 2.88G/2.88G [15:16<00:00, 3.37MiB/s]\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Gabriel\\.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcrição:  Eu não me abro em longa, eu não estou em longa Os mais íntimos me chamam de pila, escuta só Eu curto com meu trans na baixa e escondido da minha namorada E isso não tem problema, porque ela conhece o esquema Não dou meu braço a você e dou o cu a roer Matheus Duarte, quem me introduziu a essa vida Já comi o neguinho na baixa e eles me chamam de pila De segunda a sexta, estou com a minha amada Mas no sábado eu gosto de dar uma bimbada com transitais Matheus Duarte, quem me introduziu a essa vida Já comi o neguinho na baixa e eles me chamam de pila De segunda a sexta, estou com a minha amada Mas no sábado eu gosto de dar uma bimbada De dar uma bimbada com transitais É tudo resenha, pilunga, não fique bravo Meu nome é Bilunga e eu gosto de comer viado Tudo resenha, pilunga, não fique bravo Meu nome é Bilunga e eu gosto de comer viado Eu curto com meu trans na baixa e escondido da minha namorada E isso não tem problema, porque ela conhece o esquema Não dou meu braço a você e dou o cu a roer Matheus Duarte, quem me introduziu a essa vida Já comi o neguinho na baixa e eles me chamam de pila De segunda a sexta, estou com a minha amada Mas no sábado eu gosto de dar uma bimbada com transitais Matheus Duarte É tudo resenha, pilunga, não fique bravo Meu nome é Bilunga e eu gosto de comer viado\n",
      "Resumo:  Matheus Duarte, quem me introduziu a essa vida Já comi o neguinho na baixa e eles me chamam de pila De segunda a sexta, estou com a minha amada Mas no sábado eu gosto de dar uma bimbada . Eu curto com meu trans na baikea e escondido da minha namorada E isso não tem problema, porque ela conhecece o esquema .\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "from transformers import pipeline\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Carregar o modelo Whisper\n",
    "modelo_whisper = whisper.load_model(\"large\")\n",
    "\n",
    "# Função para converter áudio para .wav usando ffmpeg\n",
    "def converter_para_wav(arquivo_audio):\n",
    "    arquivo_wav = \"temp_audio.wav\"\n",
    "    comando_ffmpeg = [\"ffmpeg\", \"-i\", arquivo_audio, \"-ar\", \"16000\", \"-ac\", \"1\", \"-y\", arquivo_wav]\n",
    "    subprocess.run(comando_ffmpeg, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    return arquivo_wav\n",
    "\n",
    "# Função para transcrever o áudio\n",
    "def transcrever_audio(arquivo_audio):\n",
    "    # Converte o arquivo de áudio para .wav, se necessário\n",
    "    if not arquivo_audio.endswith(\".wav\"):\n",
    "        arquivo_audio = converter_para_wav(arquivo_audio)\n",
    "    resultado = modelo_whisper.transcribe(arquivo_audio)\n",
    "    \n",
    "    # Remove o arquivo temporário .wav se foi criado\n",
    "    if \"temp_audio.wav\" in arquivo_audio:\n",
    "        os.remove(arquivo_audio)\n",
    "        \n",
    "    return resultado['text']\n",
    "\n",
    "# Função para resumir o texto\n",
    "def resumir_texto(texto):\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "    resumo = summarizer(texto, max_length=150, min_length=30, do_sample=False)\n",
    "    return resumo[0]['summary_text']\n",
    "\n",
    "# Função principal para transcrever, resumir e salvar em um arquivo .txt\n",
    "def processar_audio(arquivo_audio):\n",
    "    transcricao = transcrever_audio(arquivo_audio)\n",
    "    resumo = resumir_texto(transcricao)\n",
    "    \n",
    "    # Salvar a transcrição e o resumo em um arquivo .txt\n",
    "    with open(\"output.txt\", \"w\", encoding=\"utf-8\") as arquivo:\n",
    "        arquivo.write(\"Transcrição:\\n\")\n",
    "        arquivo.write(transcricao + \"\\n\\n\")\n",
    "        arquivo.write(\"Resumo:\\n\")\n",
    "        arquivo.write(resumo)\n",
    "    \n",
    "    print(\"Transcrição e resumo salvos em 'resumo.txt'.\")\n",
    "\n",
    "# Exemplo de uso com um arquivo mp3\n",
    "arquivo_audio = r\"C:\\Users\\Gabriel\\www\\ExerciciosPython\\audio_teste.opus\"  # substitua pelo caminho do seu arquivo de áudio\n",
    "processar_audio(arquivo_audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento concluído. Confira 'resultado_audio.txt' para o relatório completo.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "from openai import OpenAI\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Carregar o modelo Whisper\n",
    "modelo_whisper = whisper.load_model(\"large\")\n",
    "\n",
    "# Inicializar o cliente OpenAI\n",
    "client = OpenAI() # OBS: Definir API_KEY nas variaveis de ambiente\n",
    "\n",
    "# Função para converter áudio para .wav usando ffmpeg\n",
    "def converter_para_wav(arquivo_audio):\n",
    "    arquivo_wav = \"temp_audio.wav\"\n",
    "    comando_ffmpeg = [\"ffmpeg\", \"-i\", arquivo_audio, \"-ar\", \"16000\", \"-ac\", \"1\", \"-y\", arquivo_wav]\n",
    "    subprocess.run(comando_ffmpeg, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    return arquivo_wav\n",
    "\n",
    "# Função para transcrever o áudio\n",
    "def transcrever_audio(arquivo_audio):\n",
    "    # Converte o arquivo de áudio para .wav, se necessário\n",
    "    if not arquivo_audio.endswith(\".wav\"):\n",
    "        arquivo_audio = converter_para_wav(arquivo_audio)\n",
    "    resultado = modelo_whisper.transcribe(arquivo_audio)\n",
    "    return resultado['text']\n",
    "\n",
    "# Função para gerar um relatório detalhado\n",
    "def gerar_relatorio_detalhado(texto):\n",
    "    prompt = f\"Sabendo que se trata de um texto que sera encaminhado para uma secretaria municipal. Primeiro classifique o texto em algumas dessas opções: Meio Ambiente, Educação, Fazenda, Infraestrutura, Abastecimento pesca e agricultura, Turismo, Saúde, Esporte. Depois escreva uma subcategoria. Em seguida defina o tema principal abordado. Após esses dois passos, faça um resumo bem objetivo. Um exemplo hipotetico seria: Categoria: infraestrutura Subcategoria: praças Tema: iluminação Assunto principal: “puxar do texto”. De acordo com o que informei, realize o processo com o seguinte conteúdo: {texto}\"\n",
    "    \n",
    "    # Fazendo a chamada à API da OpenAI\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Verificando se o retorno tem o formato esperado\n",
    "    try:\n",
    "        relatorio = response.choices[0].message.content\n",
    "    except AttributeError:\n",
    "        print(\"A resposta da API não está no formato esperado.\")\n",
    "        relatorio = \"Erro ao gerar o relatório.\"\n",
    "    return relatorio\n",
    "\n",
    "# Função principal para transcrever e gerar relatório\n",
    "def processar_audio(arquivo_audio):\n",
    "    transcricao = transcrever_audio(arquivo_audio)\n",
    "    relatorio = gerar_relatorio_detalhado(transcricao)\n",
    "    \n",
    "    # Salvar transcrição e relatório em um arquivo .txt\n",
    "    with open(\"resultado_audio.txt\", \"w\", encoding=\"utf-8\") as arquivo:\n",
    "        # arquivo.write(\"Transcrição:\\n\")\n",
    "        # arquivo.write(transcricao + \"\\n\\n\")\n",
    "        arquivo.write(\"Relatório Detalhado:\\n\")\n",
    "        arquivo.write(relatorio)\n",
    "        \n",
    "    print(\"Processamento concluído. Confira 'resultado_audio.txt' para o relatório completo.\")\n",
    "\n",
    "# Exemplo de uso com um arquivo mp3\n",
    "arquivo_audio = \"C:\\\\Users\\\\Gabriel\\\\www\\\\AudioAI\\\\audio_teste2.opus\"  # substitua pelo caminho do seu arquivo de áudio\n",
    "processar_audio(arquivo_audio)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
